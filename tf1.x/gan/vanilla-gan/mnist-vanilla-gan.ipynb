{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17504398570367115282\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6709723791\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2507504436574865562\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:08:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 28 # Height of the image\n",
    "WIDTH = 28 # Width of the image\n",
    "CHANNELS = 1 # Number of channels for an image\n",
    "\n",
    "Z_DIM = 100 # Dimensions of noise vector z\n",
    "BATCH_SIZE = 128 # Batch size for training\n",
    "\n",
    "D_LEARNING_RATE = 2e-4\n",
    "G_LEARNING_RATE = 2e-4\n",
    "N_EPOCHS = 300\n",
    "BETA1 = 0.5\n",
    "G_ITERS = 1\n",
    "RUN_NAME = f\"vanilla_NO_BN_d_lr{D_LEARNING_RATE}_g_lr{G_LEARNING_RATE}_{BETA1}_{G_ITERS}_{N_EPOCHS}\"\n",
    "SAVE_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_dir = 'C:\\\\Users\\\\Jonathan\\\\Documents\\\\development\\\\datasets\\\\images\\\\mnist\\\\training'\n",
    "image_list = []\n",
    "for directory in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']:\n",
    "    for root, d, files in os.walk(os.path.join(image_dir, directory)):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_list.append(os.path.join(directory, file))\n",
    "\n",
    "plt.imshow(cv2.imread(os.path.join(image_dir, image_list[0])))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(images, rows=8, cols=8):\n",
    "    grid = np.zeros([images.shape[1] * rows, images.shape[2] * cols])\n",
    "    \n",
    "    if rows * cols > images.shape[0]:\n",
    "        return\n",
    "    \n",
    "    i = 0\n",
    "    for y in range(0, grid.shape[0], images.shape[1]):\n",
    "        for x in range(0, grid.shape[1], images.shape[2]):\n",
    "            grid[y:y+images.shape[1], x:x + images.shape[2]] = images[i]\n",
    "            i += 1\n",
    "    return grid\n",
    "\n",
    "def plot_images(images, rows=8, cols=8):\n",
    "    grid = make_grid(images, rows, cols)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(grid, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list = image_list[:59904]\n",
    "len(image_list) / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_layers = [256, HEIGHT * WIDTH]\n",
    "d_layers = [256, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def inverse_transform(image):\n",
    "    return ((image + 1.) / 2.).clip(0, 1)\n",
    "\n",
    "def transform(image):\n",
    "    return ((image * 2. - 1.)).clip(-1, 1)\n",
    "\n",
    "def generator(z, layers, training=True, reuse=False):\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse) as scope:\n",
    "        for i in range(len(layers) - 1):\n",
    "            z = tf.layers.dense(z, layers[i], use_bias=True, name=f'g_h{i}')\n",
    "            z = tf.nn.relu(z)\n",
    "        \n",
    "        z = tf.layers.dense(z, layers[-1], use_bias=True, name=f'g_h{len(layers) - 1}')\n",
    "        z = tf.nn.tanh(z)\n",
    "        return z\n",
    "    \n",
    "def discriminator(x, layers, training=True, reuse=False):\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse) as scope:\n",
    "        for i in range(len(layers) - 1):\n",
    "            x = tf.layers.dense(x, layers[i], use_bias=True, name=f'd_h{i}')\n",
    "            x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "            \n",
    "        x = tf.layers.dense(x, layers[-1], use_bias=True, name=f'd_h{len(layers) - 1}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(image):\n",
    "    return ((image + 1.) / 2.).clip(0, 1)\n",
    "\n",
    "def transform(image):\n",
    "    return ((image * 2. - 1.)).clip(-1, 1)\n",
    "\n",
    "def generator(z, layers, training=True, reuse=False):\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse) as scope:\n",
    "        for i in range(len(layers) - 1):\n",
    "            z = tf.layers.dense(z, layers[i], use_bias=True, \n",
    "                                kernel_initializer=tf.initializers.truncated_normal(mean=0, stddev=0.02),\n",
    "                                name=f'g_h{i}')\n",
    "            z = tf.nn.relu(z)\n",
    "        \n",
    "        z = tf.layers.dense(z, layers[-1], use_bias=True, name=f'g_h{len(layers) - 1}')\n",
    "        z = tf.nn.tanh(z)\n",
    "        return z\n",
    "    \n",
    "def discriminator(x, layers, training=True, reuse=False):\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse) as scope:\n",
    "        for i in range(len(layers) - 1):\n",
    "            x = tf.layers.dense(x, layers[i], use_bias=True, \n",
    "                                kernel_initializer=tf.initializers.truncated_normal(mean=0, stddev=0.02),\n",
    "                                name=f'd_h{i}')\n",
    "            x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "            \n",
    "        x = tf.layers.dense(x, layers[-1], use_bias=True, name=f'd_h{len(layers) - 1}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dce14c369c9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHEIGHT\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mg_fixed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_fixed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mreal_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-8217d3f30b51>\u001b[0m in \u001b[0;36mgenerator\u001b[1;34m(z, layers, training, reuse)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             z = tf.layers.dense(z, layers[i], use_bias=True, \n\u001b[1;32m---> 11\u001b[1;33m                                 \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                                 name=f'g_h{i}')\n\u001b[0;32m     13\u001b[0m             \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'initializer'"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    z = tf.placeholder(tf.float32, shape=[None, Z_DIM])\n",
    "    z_fixed = tf.placeholder(tf.float32, shape=[None, Z_DIM])\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, HEIGHT * WIDTH])\n",
    "    \n",
    "    g = generator(z, g_layers, training=True, reuse=False)\n",
    "    g_fixed = generator(z_fixed, g_layers, training=False, reuse=True)\n",
    "    real_logits = discriminator(x, d_layers, training=True, reuse=False)\n",
    "    fake_logits = discriminator(g, d_layers, training=True, reuse=True)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_logits, \n",
    "                                                                         labels=tf.ones_like(real_logits)))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, \n",
    "                                                                         labels=tf.zeros_like(fake_logits)))\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, \n",
    "                                                                    labels=tf.ones_like(fake_logits)))\n",
    "    \n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    d_loss_real_summary = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n",
    "    d_loss_fake_summary = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n",
    "    g_loss_summary = tf.summary.scalar(\"g_loss\", g_loss)\n",
    "    d_loss_summary = tf.summary.scalar(\"d_loss\", d_loss)\n",
    "    images_summary = tf.summary.image(\"generated_images\", tf.reshape((g_fixed + 1.) / 2., [BATCH_SIZE, HEIGHT, WIDTH, 1]))\n",
    "    \n",
    "    trainable_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in trainable_vars if 'discriminator' in var.name]\n",
    "    g_vars = [var for var in trainable_vars if 'generator' in var.name]\n",
    "    \n",
    "    print(d_vars)\n",
    "    print(g_vars)\n",
    "    \n",
    "    d_optim = tf.train.AdamOptimizer(D_LEARNING_RATE, beta1=BETA1)\\\n",
    "                    .minimize(d_loss, var_list=d_vars)\n",
    "    g_optim = tf.train.AdamOptimizer(G_LEARNING_RATE, beta1=BETA1)\\\n",
    "                    .minimize(g_loss, var_list=g_vars)\n",
    "    \n",
    "    d_summary = tf.summary.merge([d_loss_real_summary, d_loss_fake_summary, d_loss_summary])\n",
    "    g_summary = tf.summary.merge([g_loss_summary, images_summary])\n",
    "    \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    writer = tf.summary.FileWriter(\"./runs/{}\".format(RUN_NAME), sess.graph)\n",
    "    summary_step = 0\n",
    "    \n",
    "    if SAVE_PATH:\n",
    "        saver.restore(sess, SAVE_PATH)\n",
    "    else:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "    \n",
    "    z_fixed_input = np.random.uniform(-1, 1, [BATCH_SIZE, Z_DIM])\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        np.random.shuffle(image_list)\n",
    "        i = 0\n",
    "        while i < len(image_list):\n",
    "            x_input = np.zeros([BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\n",
    "            for k in range(0, BATCH_SIZE):\n",
    "                x_input[k] = cv2.imread(\n",
    "                                os.path.join(image_dir, image_list[i + k])\n",
    "                                )[:, :, [0]]\n",
    "            \n",
    "            x_input = transform(x_input / 255).reshape(BATCH_SIZE, -1)\n",
    "            z_input = np.random.uniform(-1, 1, [BATCH_SIZE, Z_DIM])\n",
    "            \n",
    "            [_, d_summary_result, d_loss_val, dlrv, dlfv] = sess.run([d_optim, d_summary, d_loss, d_loss_real, d_loss_fake], feed_dict={z: z_input, x: x_input})\n",
    "            \n",
    "            for _ in range(G_ITERS):\n",
    "                [_, g_img, g_summary_result] = sess.run([g_optim, g_fixed, g_summary], feed_dict={z: z_input,\n",
    "                                                                                                   z_fixed: z_fixed_input,\n",
    "                                                                                                   x: x_input})                \n",
    "            if (i % (BATCH_SIZE * 50) == 0):\n",
    "                writer.add_summary(g_summary_result, summary_step)\n",
    "                writer.add_summary(d_summary_result, summary_step)\n",
    "                summary_step += 1\n",
    "            \n",
    "            i += BATCH_SIZE\n",
    "            \n",
    "        if epoch % 5 == 0:\n",
    "            plot_images(inverse_transform(g_img.reshape(BATCH_SIZE, HEIGHT, WIDTH)))\n",
    "            cv2.imwrite(f'./results/{epoch}.jpg', make_grid(inverse_transform(g_img.reshape(BATCH_SIZE, HEIGHT, WIDTH))))\n",
    "\n",
    "        save_path = saver.save(sess, \"./checkpoints/{}\".format(RUN_NAME))\n",
    "        print(f\"[Epoch {epoch}/{N_EPOCHS}] -- Saved {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.initializers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(x_input.reshape(BATCH_SIZE, HEIGHT, WIDTH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
